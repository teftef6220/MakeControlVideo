import sys
import os
sys.path.append(os.path.abspath("."))

from dotenv import load_dotenv
import json
import random
import numpy as np
import subprocess
import argparse
from yt_dlp import YoutubeDL

import torch
from tqdm import tqdm
from shutil import rmtree

from transformers import (
    Qwen2_5_VLForConditionalGeneration,
    AutoModelForCausalLM,
    AutoTokenizer,
    AutoProcessor,
    BitsAndBytesConfig,
)
from dwpose import DwposeDetector, AnimalposeDetector

from Utils.create_data_utils import generate_caption, apply_dwpose
from Utils.path_utils import resolve_output_path , collect_video_paths


def download_and_clip_videos(args, json_path, output_dir, base_duration, delta):
    """
    YouTube ã¾ãŸã¯ãƒ­ãƒ¼ã‚«ãƒ«ã®å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€æŒ‡å®šã•ã‚ŒãŸç§’æ•°ã§åˆ‡ã‚Šå‡ºã™
    input
        args: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°
        json_path: å‹•ç”»URLã‚’å«ã‚€JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        output_dir: å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        base_duration: åŸºæº–ç§’æ•° (n)
        delta: è¨±å®¹èª¤å·®ç§’æ•° (Â±delta)
    output
        metadata_entries: å‹•ç”»ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€jsonãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    #### ================== 
    ##   0. Set up Directories
    #### ================== 
    # path ãƒã‚§ãƒƒã‚¯ã€ã“ã® Ripo ã‹ã‚‰ã®ç›¸å¯¾ path ã«å¤‰æ›
    resolve_output_path(output_dir)

    # output ã®è¦ªã€€path
    os.makedirs(output_dir, exist_ok=True)

    # å‹•ç”» clip path
    os.makedirs("temp", exist_ok=True)
    output_json_path = os.path.join(output_dir, args.metadata_json_name)
    output_clip_video_path = os.path.join(output_dir, "clip_video")
    os.makedirs(output_clip_video_path, exist_ok=True)

    # å¿…è¦ãªã‚‰ã° control path
    control_dir = os.path.join(output_dir, "control") if args.do_dwpose else None
    if control_dir:
        os.makedirs(control_dir, exist_ok=True)
    
    #### ================== 
    ##   1. Set up part
    #### ================== 
    # Load LLM
    if args.do_caption:
        bf16_supported = (
            torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8
        )
        model_path = os.path.join(os.environ['LLM_PATH'], args.llm_dir)
        processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)
        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16 if bf16_supported else torch.float16,
            device_map="auto",
            trust_remote_code=True,
            attn_implementation="eager"
        )

    # Load DWpose
    if args.do_dwpose:
        pose_model = DwposeDetector.from_pretrained(
            pretrained_model_or_path="yzd-v/DWPose",
            pretrained_det_model_or_path="yzd-v/DWPose",
            det_filename="yolox_l.onnx",
            pose_filename="dw-ll_ucoco_384.onnx",
            torchscript_device=torch.device("cuda" if torch.cuda.is_available() else "cpu")
        )

    if args.use_wd14_tagger:
        pass
    #### ================== 
    ##   2. Download and clip videos part
    #### ================== 

    if args.use_youtube_data:
        print(f"Use Yoube mode. ğŸ“„ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {json_path}")
        with open(json_path, "r") as f:
            video_data = json.load(f)
        data_list = video_data["videos"]
    else:
        print(f"Use self data mode. ğŸ“‚ è‡ªåˆ†ã®å‹•ç”»ã‚’èª­ã¿è¾¼ã¿ä¸­: {args.self_data_path}")
        self_data_list = collect_video_paths(args.self_data_path)
        data_list = self_data_list


    if args.data_count > 0:
        try:
            if os.path.exists(output_json_path):
                with open(output_json_path, "r", encoding="utf-8") as f:
                    metadata_entries = json.load(f)
                    video_index = len(metadata_entries) + 1
            else:
                print(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ã‹å£Šã‚Œã¦ã„ã¾ã™ã€‚æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’1ã‹ã‚‰é–‹å§‹ã—ã¾ã™ã€‚")
                video_index = 1
        except (json.JSONDecodeError, IOError):
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒå£Šã‚Œã¦ã„ã‚‹ãƒ»ç©ºãƒ»èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
            print(f"âŒ èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’1ã‹ã‚‰é–‹å§‹ã—ã¾ã™ã€‚")
            video_index = 1
    else:
        video_index = 1


    metadata_entries = []
    for url in data_list:
        try:
            with YoutubeDL({
                'format': 'mp4',
                'outtmpl': 'temp/%(id)s.%(ext)s',
                'quiet': True,
            }) as ydl:
                info = ydl.extract_info(url, download=True)
                video_path = f"temp/{info['id']}.mp4"
                duration = info.get("duration", 0)

            result_video_path_list = []
            new_entries = []

            #### ================== 
            ##   2.1 Clip videos
            #### ================== 
            for _ in range(args.num_clips_per_videos):
                clip_duration = random.uniform(base_duration - delta, base_duration + delta)
                if duration <= clip_duration:
                    raise ValueError(f"URL {url} is too short for {clip_duration:.2f}s clipping.")

                start_time = random.uniform(0, duration - clip_duration)
                filename = f"{video_index:08d}.mp4"
                output_file_path = os.path.join(output_clip_video_path, filename)

                subprocess.run([
                    "ffmpeg", "-ss", str(start_time),
                    "-i", video_path,
                    "-t", str(clip_duration),
                    "-c:v", "libx264", "-c:a", "aac", "-y",
                    output_file_path
                ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

                print(f"âœ… Finish : {output_file_path}")
                result_video_path_list.append(output_file_path)

                entry = {
                    "file_path": os.path.join(os.environ['BASE_PATH'], output_file_path),
                    "type": "video",
                    "filename": filename,
                    "text": "",
                    "control_file_path": ""
                }
                new_entries.append(entry)
                video_index += 1

            # Generate captions
            if args.do_caption:
                captions = generate_caption(args, model, processor, result_video_path_list, os.environ['LLM_PATH'])
                for entry, caption in zip(new_entries, captions):
                    entry["text"] = caption

            # Apply DWpose
            if args.do_dwpose:
                control_paths = apply_dwpose(args, pose_model, result_video_path_list, control_dir)
                for entry, control_path in zip(new_entries, control_paths):
                    entry["control_file_path"] = os.path.join(os.environ['BASE_PATH'], control_path)

            # âœ… æˆåŠŸã—ãŸã‚‰ä¿å­˜
            metadata_entries.extend(new_entries)
            with open(output_json_path, "w") as f:
                json.dump(metadata_entries, f, indent=2)
            print(f"ğŸ“„ ä¿å­˜: {output_json_path}")

            # temp ã®ä¸­èº«æ¶ˆã™ (temp ã¯æ®‹ã™)
            if os.path.isfile(video_path):
                os.remove(video_path)
                print(f"{video_path} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
            else:
                print(f"{video_path} ã¯å­˜åœ¨ã—ãªã„ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        except Exception as e:
            print(f"âŒ Skipped URL due to error: {url}")
            print(f"   Reason: {e}")
    
    # temp ãƒ•ã‚©ãƒ«ãƒ€å‰Šé™¤
    print("temp ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤ã—ã¾ã™ã€‚")
    rmtree("temp", ignore_errors=True)

    print(" ================= Finish !!!! ===================== ")
    print(f" make {video_index - 1} videos")
    print(f" metadata json file saved in : {output_json_path}")
    print(f" video clip saved in : {output_clip_video_path}")
    print(f" control video saved in : {control_dir}" if control_dir else "No control video")

if __name__ == "__main__":
    load_dotenv()
    print(os.environ['BASE_PATH'])
    
    parser = argparse.ArgumentParser(description="YouTubeå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦nÂ±Î´ç§’ã§åˆ‡ã‚Šå‡ºã™ãƒ„ãƒ¼ãƒ«")
    parser.add_argument('--use_youtube_data', type=bool, default=True, help="YouTubeå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ‡ã‚Šå‡ºã™ã‹ã€æ—¢å­˜ã®å‹•ç”»ã‚’åˆ‡ã‚Šå‡ºã™ã‹")
    parser.add_argument('--json',default='json_files/proto_test.json', help='å‹•ç”»URLã‚’å«ã‚€JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--self_data_path', default='path/to/your/self/data', help='è‡ªåˆ†ã®å‹•ç”»ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹youtube ã‚’ä½¿ã†ã¨ãã¯é–¢ä¿‚ãªã„')
    parser.add_argument('--outdir', default='Result_data/proto_2', help='out put dir ç›¸å¯¾path æ¨å¥¨')
    parser.add_argument('--metadata_json_name', default='proto_2_metadeta.json', help='metadata json file')
    parser.add_argument('--n', type=float, default=1.0, help='åŸºæº–ç§’æ•° (n)')
    parser.add_argument('--delta', type=float, default=0.0, help='è¨±å®¹èª¤å·®ç§’æ•° (Â±delta)')
    parser.add_argument('--num_clips_per_videos', type=int, default=2, help='å„å‹•ç”»ã‹ã‚‰åˆ‡ã‚Šå‡ºã™ã‚¯ãƒªãƒƒãƒ—ã®æ•°')
    parser.add_argument('--data_count', type=int, default=0, help='ãƒ‡ãƒ¼ã‚¿ã«ä»˜ã‘ã‚‹indexç•ªå·ã®ã¯ã˜ã‚ã‚’æŒ‡å®šã™ã‚‹ã‹ã€1 ä»¥ä¸Šã‚’æŒ‡å®šã™ã‚‹ã¨é€”ä¸­ã‹ã‚‰åˆ¤å®šã•ã‚Œã‚‹')

    ## LLM Caption
    parser.add_argument('--do_caption', type=bool, default=False,help="Do caotion generation")
    parser.add_argument('--llm_dir', default='Qwen2_5-VL-7B-Instruct', help='llm qwen 2.1 VL model dir')
    parser.add_argument('--prompt', type=str, default="Describe this video.", help='default prompt for caption generation')
    parser.add_argument('--dufault_caption', type=str, default="", help='default caption to add front of data')

    ## DWpose
    parser.add_argument('--do_dwpose', type=bool, default=True,help="Do dwpose estimation")

    ## WD14 Tagger
    parser.add_argument('--use_wd14_tagger', type=bool, default=False, help="Use wd14 tagger")
    
    args = parser.parse_args()
    download_and_clip_videos(args, args.json, args.outdir, args.n, args.delta)
